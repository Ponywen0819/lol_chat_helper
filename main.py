import os
import uuid
import asyncio
import logging
from datetime import datetime
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import START, MessagesState, StateGraph
from langgraph.prebuilt import ToolNode, tools_condition

from mcp_manager import MCPToolManager


# Load environment variables
load_dotenv()

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def create_chatbot():
    """Create and configure the chatbot with memory and MCP tools."""

    # Initialize the LM Studio chat model
    model = ChatOpenAI(
        base_url=os.getenv("LM_STUDIO_BASE_URL", "http://localhost:1234/v1"),
        api_key=os.getenv("OPENAI_API_KEY", "lm-studio"),
        model="gpt-oss:20b",
        temperature=0.7,
        streaming=False,
    )

    # Initialize MCP Tool Manager
    mcp_manager = None
    tools = []
    mcp_enabled = os.getenv("MCP_ENABLED", "true").lower() == "true"

    if mcp_enabled:
        try:
            logger.info("æ­£åœ¨åˆå§‹åŒ– MCP å·¥å…·ç®¡ç†å™¨...")
            mcp_config_path = os.getenv("MCP_CONFIG_PATH", "mcp_config.json")
            mcp_manager = MCPToolManager(mcp_config_path)
            tools = await mcp_manager.initialize()
            logger.info(f"æˆåŠŸè¼‰å…¥ {len(tools)} å€‹ MCP å·¥å…·")
        except Exception as e:
            logger.warning(f"MCP åˆå§‹åŒ–å¤±æ•—ï¼Œå°‡ä»¥ç´”èŠå¤©æ¨¡å¼é‹è¡Œ: {e}")
            logger.warning("å¦‚éœ€ä½¿ç”¨ MCP å·¥å…·ï¼Œè«‹ç¢ºä¿ï¼š")
            logger.warning("1. Node.js å·²å®‰è£ä¸”å¯åŸ·è¡Œ npx")
            logger.warning("2. ç¶²è·¯å¯ä»¥è¨ªå• https://mcp-api.op.gg/mcp")
            logger.warning("3. mcp_config.json é…ç½®æ­£ç¢º")
            mcp_manager = None
            tools = []

    # Get current date information
    current_date = datetime.now()
    date_info = (
        f"ç•¶å‰æ—¥æœŸï¼š{current_date.year}å¹´{current_date.month}æœˆ{current_date.day}æ—¥\n"
        f"æ˜ŸæœŸï¼š{['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'æ—¥'][current_date.weekday()]}\n"
    )

    # Define system prompt
    if tools:
        system_prompt = (
            "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„è‹±é›„è¯ç›Ÿï¼ˆLeague of Legends, LOLï¼‰åŠ©æ‰‹ï¼Œå…·å‚™è¨˜æ†¶åŠŸèƒ½ã€‚\n"
            "ä½ å¯ä»¥ä½¿ç”¨ OP.GG çš„å·¥å…·ä¾†æŸ¥è©¢ç©å®¶è³‡è¨Šã€è‹±é›„æ•¸æ“šã€å°å±€æ­·å²ç­‰æœ€æ–°è³‡æ–™ã€‚\n\n"
            f"{date_info}\n"
            "å¯ç”¨å·¥å…·åŒ…æ‹¬ï¼š\n"
            "- å¬å–šå¸«æŸ¥è©¢ï¼šæŸ¥è©¢ç©å®¶çš„åŸºæœ¬è³‡è¨Šå’Œçµ±è¨ˆæ•¸æ“š\n"
            "- å°å±€æ­·å²ï¼šç²å–ç©å®¶æœ€è¿‘çš„å°å±€è¨˜éŒ„\n"
            "- è‹±é›„åˆ†æï¼šåˆ†æè‹±é›„çš„ counterã€ban/pick æ•¸æ“š\n"
            "- è‹±é›„ meta æ•¸æ“šï¼šç²å–è‹±é›„çš„çµ±è¨ˆå’Œè¡¨ç¾æŒ‡æ¨™\n"
            "- ä½ç½®çµ±è¨ˆï¼šæŸ¥è©¢è‹±é›„åœ¨å„ä½ç½®çš„æ•¸æ“š\n"
            "- æ’è¡Œæ¦œï¼šç²å–è‹±é›„æ’è¡Œæ¦œè³‡è¨Š\n"
            "- é€ å‹ç‰¹åƒ¹ï¼šæŸ¥è©¢ç‰¹åƒ¹çš„è‹±é›„é€ å‹\n"
            "- æ›´æ–°æ•¸æ“šï¼šæ›´æ–°å¬å–šå¸«çš„æœ€æ–°è³‡æ–™\n\n"
            "ç•¶ä½¿ç”¨è€…è©¢å• LOL ç›¸é—œè³‡è¨Šæ™‚ï¼Œä½ æ‡‰è©²ä¸»å‹•ä½¿ç”¨é©ç•¶çš„å·¥å…·ä¾†ç²å–æœ€æ–°æ•¸æ“šã€‚\n"
            "è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”å•é¡Œï¼Œä¸¦è¨˜ä½ä¹‹å‰çš„å°è©±å…§å®¹ã€‚"
        )
    else:
        system_prompt = (
            "ä½ æ˜¯ä¸€å€‹å‹å–„ä¸”æ¨‚æ–¼åŠ©äººçš„ AI åŠ©æ‰‹ã€‚\n"
            f"{date_info}\n"
            "è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”å•é¡Œï¼Œä¸¦è¨˜ä½ä¹‹å‰çš„å°è©±å…§å®¹ã€‚\n"
            "æ³¨æ„ï¼šç›®å‰ MCP å·¥å…·æœªå•Ÿç”¨ï¼Œç„¡æ³•æŸ¥è©¢å³æ™‚çš„ LOL è³‡æ–™ã€‚"
        )

    # Create the state graph
    workflow = StateGraph(state_schema=MessagesState)

    if tools:
        # Agent mode with tools
        def call_model(state: MessagesState):
            """Process messages and generate AI response with tool support."""
            messages = [SystemMessage(content=system_prompt)] + state["messages"]
            response = model.bind_tools(tools).invoke(messages)
            return {"messages": response}

        # Add nodes
        workflow.add_node("agent", call_model)
        workflow.add_node("tools", ToolNode(tools))

        # Add edges
        workflow.add_edge(START, "agent")
        workflow.add_conditional_edges(
            "agent",
            tools_condition,  # Automatically routes to tools if needed
        )
        workflow.add_edge("tools", "agent")

    else:
        # Simple chat mode without tools
        def call_model(state: MessagesState):
            """Process messages and generate AI response."""
            messages = [SystemMessage(content=system_prompt)] + state["messages"]
            response = model.invoke(messages)
            return {"messages": response}

        workflow.add_node("model", call_model)
        workflow.add_edge(START, "model")

    # Add memory
    memory = MemorySaver()
    app = workflow.compile(checkpointer=memory)

    return app, mcp_manager


def display_welcome(has_tools: bool = False):
    """Display welcome message and instructions."""
    print("=" * 60)
    if has_tools:
        print("  LOL Chat Helper - å…·å‚™è¨˜æ†¶åŠŸèƒ½å’Œ OP.GG å·¥å…·çš„èŠå¤©æ©Ÿå™¨äºº")
    else:
        print("  LOL Chat Helper - å…·å‚™è¨˜æ†¶åŠŸèƒ½çš„èŠå¤©æ©Ÿå™¨äºº")
    print("=" * 60)
    print("\nå¯ç”¨å‘½ä»¤:")
    print("  /quit æˆ– /exit  - é€€å‡ºç¨‹å¼")
    print("  /new           - é–‹å§‹æ–°çš„å°è©±")
    print("  /history       - é¡¯ç¤ºç•¶å‰å°è©±æ­·å²")
    if has_tools:
        print("  /tools         - é¡¯ç¤º MCP å·¥å…·ç‹€æ…‹")
    print("  /help          - é¡¯ç¤ºå¹«åŠ©è¨Šæ¯")
    print("\nè«‹ç¢ºä¿ LM Studio å·²å•Ÿå‹•ä¸¦è¼‰å…¥äº†æ¨¡å‹ï¼")
    if has_tools:
        print("OP.GG MCP å·¥å…·å·²å•Ÿç”¨ï¼Œå¯ä»¥æŸ¥è©¢ LOL å³æ™‚è³‡æ–™ï¼")
    print("-" * 60)


def display_history(app, config):
    """Display conversation history."""
    try:
        state = app.get_state(config)
        messages = state.values.get("messages", [])

        if not messages:
            print("\n[ç³»çµ±] ç›®å‰æ²’æœ‰å°è©±æ­·å²\n")
            return

        print("\n" + "=" * 60)
        print("å°è©±æ­·å²:")
        print("=" * 60)

        for msg in messages:
            if hasattr(msg, 'type'):
                if msg.type == 'human':
                    print(f"\nğŸ‘¤ ä½¿ç”¨è€…: {msg.content}")
                elif msg.type == 'ai':
                    print(f"ğŸ¤– AI: {msg.content}")
                elif msg.type == 'system':
                    print(f"âš™ï¸  ç³»çµ±: {msg.content}")
                elif msg.type == 'tool':
                    print(f"ğŸ”§ å·¥å…·: {msg.name} - {msg.content[:100]}...")

        print("\n" + "=" * 60 + "\n")
    except Exception as e:
        print(f"\n[éŒ¯èª¤] ç„¡æ³•å–å¾—å°è©±æ­·å²: {e}\n")


def display_tools_status(mcp_manager):
    """Display MCP tools status."""
    if not mcp_manager:
        print("\n[ç³»çµ±] MCP å·¥å…·æœªå•Ÿç”¨\n")
        return

    try:
        status = mcp_manager.get_tools_status()

        print("\n" + "=" * 60)
        print("OP.GG MCP å·¥å…·ç‹€æ…‹")
        print("=" * 60)
        print(f"\nç¸½è¨ˆ: {status['enabled']}/{status['total']} å·¥å…·å·²å•Ÿç”¨")
        print(f"åˆå§‹åŒ–ç‹€æ…‹: {'âœ… å·²åˆå§‹åŒ–' if status['initialized'] else 'âŒ æœªåˆå§‹åŒ–'}")

        # æŒ‰ä¼ºæœå™¨åˆ†çµ„é¡¯ç¤º
        if 'servers' in status and status['servers']:
            print("\næŒ‰ä¼ºæœå™¨åˆ†çµ„:")
            for server_name, server_info in status['servers'].items():
                print(f"\n  ğŸ“¦ {server_name} ({server_info['enabled_count']} å€‹å·¥å…·)")
                for tool_name in server_info['enabled_tools']:
                    print(f"     âœ… {tool_name}")

        # é¡¯ç¤ºæ‰€æœ‰å·¥å…·çš„è©³ç´°ç‹€æ…‹
        if status['initialized'] and status['tools']:
            print("\nè©³ç´°å·¥å…·åˆ—è¡¨:")
            enabled_tools = [t for t in status['tools'] if t['enabled']]
            disabled_tools = [t for t in status['tools'] if not t['enabled']]

            if enabled_tools:
                print("\n  âœ… å·²å•Ÿç”¨:")
                for tool in enabled_tools:
                    print(f"     â€¢ {tool['pure_name']} (ä¼ºæœå™¨: {tool['server']})")

            if disabled_tools:
                print("\n  âŒ å·²åœç”¨:")
                for tool in disabled_tools:
                    print(f"     â€¢ {tool['pure_name']} (ä¼ºæœå™¨: {tool['server']})")

        print("\n" + "=" * 60 + "\n")
    except Exception as e:
        print(f"\n[éŒ¯èª¤] ç„¡æ³•å–å¾—å·¥å…·ç‹€æ…‹: {e}\n")
        logger.error(f"å–å¾—å·¥å…·ç‹€æ…‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)


async def main_async():
    """Main chatbot loop (async version)."""
    display_welcome()

    # Create the chatbot
    try:
        app, mcp_manager = await create_chatbot()
        has_tools = mcp_manager is not None and mcp_manager._initialized

        if has_tools:
            print("\n[ç³»çµ±] èŠå¤©æ©Ÿå™¨äººå·²å•Ÿå‹•ï¼ˆå« MCP å·¥å…·ï¼‰ï¼é–‹å§‹å°è©±å§ï¼\n")
        else:
            print("\n[ç³»çµ±] èŠå¤©æ©Ÿå™¨äººå·²å•Ÿå‹•ï¼ˆç´”èŠå¤©æ¨¡å¼ï¼‰ï¼é–‹å§‹å°è©±å§ï¼\n")
    except Exception as e:
        print(f"\n[éŒ¯èª¤] ç„¡æ³•å•Ÿå‹•èŠå¤©æ©Ÿå™¨äºº: {e}")
        print("è«‹ç¢ºä¿:")
        print("1. LM Studio å·²å•Ÿå‹•")
        print("2. å·²è¼‰å…¥æ¨¡å‹")
        print("3. æœ¬åœ°ä¼ºæœå™¨æ­£åœ¨é‹è¡Œ (é è¨­: http://localhost:1234)\n")
        return

    # Generate a unique thread ID for this conversation
    thread_id = str(uuid.uuid4())
    config = {"configurable": {"thread_id": thread_id}}

    # Main conversation loop
    try:
        while True:
            try:
                # Get user input
                user_input = input("ğŸ‘¤ ä½ : ").strip()

                # Handle empty input
                if not user_input:
                    continue

                # Handle commands
                if user_input.lower() in ['/quit', '/exit']:
                    print("\n[ç³»çµ±] å†è¦‹ï¼æ„Ÿè¬ä½¿ç”¨ï¼\n")
                    break

                elif user_input.lower() == '/new':
                    thread_id = str(uuid.uuid4())
                    config = {"configurable": {"thread_id": thread_id}}
                    print("\n[ç³»çµ±] å·²é–‹å§‹æ–°çš„å°è©±\n")
                    continue

                elif user_input.lower() == '/history':
                    display_history(app, config)
                    continue

                elif user_input.lower() == '/tools':
                    display_tools_status(mcp_manager)
                    continue

                elif user_input.lower() == '/help':
                    display_welcome(has_tools)
                    continue

                # Process user message
                input_message = HumanMessage(content=user_input)

                # Get AI response
                print("ğŸ¤– AI: ", end="", flush=True)
                try:
                    output = app.invoke({"messages": [input_message]}, config)
                    ai_response = output["messages"][-1].content
                    print(ai_response)
                except Exception as e:
                    print(f"\n[éŒ¯èª¤] AI å›æ‡‰å¤±æ•—: {e}")
                    print("è«‹æª¢æŸ¥ LM Studio æ˜¯å¦æ­£å¸¸é‹ä½œã€‚\n")
                    logger.error(f"AI å›æ‡‰éŒ¯èª¤: {e}", exc_info=True)

                print()  # Empty line for readability

            except KeyboardInterrupt:
                print("\n\n[ç³»çµ±] åµæ¸¬åˆ°ä¸­æ–·è¨Šè™Ÿï¼Œæ­£åœ¨é€€å‡º...\n")
                break
            except Exception as e:
                print(f"\n[éŒ¯èª¤] ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}\n")
                logger.error(f"æœªé æœŸéŒ¯èª¤: {e}", exc_info=True)

    finally:
        # Cleanup MCP resources
        if mcp_manager:
            await mcp_manager.cleanup()


def main():
    """Main entry point."""
    asyncio.run(main_async())


if __name__ == "__main__":
    main()
