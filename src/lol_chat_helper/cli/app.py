"""Main chat application."""

import uuid
import asyncio
from typing import Optional

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

from ..config import AppConfig, logger
from ..mcp import MCPToolManager
from ..graph import build_lol_agent
from .display import display_welcome
from .commands import CommandHandler


class ChatApp:
    """ä¸»è¦çš„èŠå¤©æ‡‰ç”¨ç¨‹å¼"""

    def __init__(self, config: Optional[AppConfig] = None):
        """
        åˆå§‹åŒ–èŠå¤©æ‡‰ç”¨ç¨‹å¼

        Args:
            config: æ‡‰ç”¨ç¨‹å¼é…ç½®ï¼ˆå¦‚æœªæä¾›å‰‡å¾ç’°å¢ƒè®Šæ•¸è¼‰å…¥ï¼‰
        """
        self.config = config or AppConfig.from_env()
        self.app = None
        self.mcp_manager: Optional[MCPToolManager] = None
        self.command_handler: Optional[CommandHandler] = None
        self.has_tools = False

    async def initialize(self):
        """åˆå§‹åŒ–æ‡‰ç”¨ç¨‹å¼ï¼ˆéåŒæ­¥ï¼‰"""
        # åˆå§‹åŒ–æ¨¡å‹
        logger.info("æ­£åœ¨åˆå§‹åŒ–èªè¨€æ¨¡å‹...")
        model = ChatOpenAI(
            base_url=self.config.model.base_url,
            api_key=self.config.model.api_key,
            model=self.config.model.model_name,
            temperature=self.config.model.temperature,
            streaming=self.config.model.streaming,
        )

        # åˆå§‹åŒ– MCP å·¥å…·
        tools = []
        if self.config.mcp.enabled:
            try:
                logger.info("æ­£åœ¨åˆå§‹åŒ– MCP å·¥å…·ç®¡ç†å™¨...")
                self.mcp_manager = MCPToolManager(self.config.mcp.config_path)
                tools = await self.mcp_manager.initialize()
                self.has_tools = True
                logger.info(f"æˆåŠŸè¼‰å…¥ {len(tools)} å€‹ MCP å·¥å…·")
            except Exception as e:
                logger.warning(f"MCP åˆå§‹åŒ–å¤±æ•—ï¼Œå°‡ä»¥ç´”èŠå¤©æ¨¡å¼é‹è¡Œ: {e}")
                logger.warning("å¦‚éœ€ä½¿ç”¨ MCP å·¥å…·ï¼Œè«‹ç¢ºä¿ï¼š")
                logger.warning("1. Node.js å·²å®‰è£ä¸”å¯åŸ·è¡Œ npx")
                logger.warning("2. ç¶²è·¯å¯ä»¥è¨ªå• https://mcp-api.op.gg/mcp")
                logger.warning("3. mcp_config.json é…ç½®æ­£ç¢º")
                self.mcp_manager = None
                tools = []
                self.has_tools = False

        # å»ºæ§‹ graph
        logger.info("æ­£åœ¨å»ºæ§‹ agent graph...")
        self.app = build_lol_agent(model=model, tools=tools, enable_memory=True)

        # åˆå§‹åŒ–å‘½ä»¤è™•ç†å™¨
        self.command_handler = CommandHandler(self.app, self.mcp_manager)

        if self.has_tools:
            logger.info("èŠå¤©æ©Ÿå™¨äººå·²å•Ÿå‹•ï¼ˆå« MCP å·¥å…·ï¼‰")
        else:
            logger.info("èŠå¤©æ©Ÿå™¨äººå·²å•Ÿå‹•ï¼ˆç´”èŠå¤©æ¨¡å¼ï¼‰")

    async def run_async(self):
        """åŸ·è¡ŒèŠå¤©æ‡‰ç”¨ç¨‹å¼ï¼ˆéåŒæ­¥ç‰ˆæœ¬ï¼‰"""
        # é¡¯ç¤ºæ­¡è¿è¨Šæ¯
        display_welcome(self.has_tools)

        # åˆå§‹åŒ–æ‡‰ç”¨ç¨‹å¼
        try:
            await self.initialize()
            if self.has_tools:
                print("\n[ç³»çµ±] èŠå¤©æ©Ÿå™¨äººå·²å•Ÿå‹•ï¼ˆå« MCP å·¥å…·ï¼‰ï¼é–‹å§‹å°è©±å§ï¼\n")
            else:
                print("\n[ç³»çµ±] èŠå¤©æ©Ÿå™¨äººå·²å•Ÿå‹•ï¼ˆç´”èŠå¤©æ¨¡å¼ï¼‰ï¼é–‹å§‹å°è©±å§ï¼\n")
        except Exception as e:
            print(f"\n[éŒ¯èª¤] ç„¡æ³•å•Ÿå‹•èŠå¤©æ©Ÿå™¨äºº: {e}")
            print("è«‹ç¢ºä¿:")
            print("1. LM Studio å·²å•Ÿå‹•")
            print("2. å·²è¼‰å…¥æ¨¡å‹")
            print("3. æœ¬åœ°ä¼ºæœå™¨æ­£åœ¨é‹è¡Œ (é è¨­: http://localhost:1234)\n")
            return

        # ç”Ÿæˆå°è©±åŸ·è¡Œç·’ ID
        thread_id = str(uuid.uuid4())
        config = {"configurable": {"thread_id": thread_id}}

        # ä¸»è¦å°è©±å¾ªç’°
        try:
            while True:
                try:
                    # å–å¾—ä½¿ç”¨è€…è¼¸å…¥
                    user_input = input("ğŸ‘¤ ä½ : ").strip()

                    # è™•ç†ç©ºè¼¸å…¥
                    if not user_input:
                        continue

                    # è™•ç†å‘½ä»¤
                    if self.command_handler.is_command(user_input):
                        should_exit, new_config = self.command_handler.handle_command(
                            user_input, config
                        )
                        if should_exit:
                            break
                        if new_config:
                            config = new_config
                        continue

                    # è™•ç†ä½¿ç”¨è€…è¨Šæ¯
                    input_message = HumanMessage(content=user_input)

                    # å–å¾— AI å›æ‡‰
                    print("ğŸ¤– AI: ", end="", flush=True)
                    try:
                        output = await self.app.ainvoke({"messages": [input_message]}, config)
                        ai_response = output["messages"][-1].content
                        print(ai_response)
                    except Exception as e:
                        print(f"\n[éŒ¯èª¤] AI å›æ‡‰å¤±æ•—: {e}")
                        print("è«‹æª¢æŸ¥ LM Studio æ˜¯å¦æ­£å¸¸é‹ä½œã€‚\n")
                        logger.error(f"AI å›æ‡‰éŒ¯èª¤: {e}", exc_info=True)

                    print()  # ç©ºè¡Œå¢åŠ å¯è®€æ€§

                except KeyboardInterrupt:
                    print("\n\n[ç³»çµ±] åµæ¸¬åˆ°ä¸­æ–·è¨Šè™Ÿï¼Œæ­£åœ¨é€€å‡º...\n")
                    break
                except Exception as e:
                    print(f"\n[éŒ¯èª¤] ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}\n")
                    logger.error(f"æœªé æœŸéŒ¯èª¤: {e}", exc_info=True)

        finally:
            # æ¸…ç†è³‡æº
            if self.mcp_manager:
                await self.mcp_manager.cleanup()

    def run(self):
        """åŸ·è¡ŒèŠå¤©æ‡‰ç”¨ç¨‹å¼ï¼ˆåŒæ­¥å…¥å£é»ï¼‰"""
        asyncio.run(self.run_async())
